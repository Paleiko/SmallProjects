{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 startet.\n",
      "Aktuelle Seite: https://www.immobilienscout24.de/Suche/S-2/P-1/Haus-Kauf\n",
      "Exportiert CSV\n",
      "Loop 1 endet.\n",
      "\n",
      "FERTIG!\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.DataFrame()\n",
    "l=[]\n",
    "number_of_results = 0\n",
    "\n",
    "try:\n",
    "\n",
    "    base_URL = \"https://www.immobilienscout24.de/\"\n",
    "    soup = bs.BeautifulSoup(urllib.request.urlopen(base_URL + \"Suche/S-1/Haus-Kauf/Nordrhein-Westfalen/Paderborn-Kreis/Paderborn/5,00-/130,00-/EURO--400000,00?enteredFrom=result_list\").read(),'lxml')\n",
    "    for result_count in soup.find_all(\"span\"):\n",
    "        if r\"resultlist-resultCount\" in str(result_count.get(\"data-is24-qa\")):\n",
    "            number_of_results = int(result_count.text)\n",
    "    \n",
    "    for seite in range(1, (number_of_results//21) + 2):\n",
    "    \n",
    "        print(\"Loop \" + str(seite) + \" startet.\")\n",
    "        \n",
    "        soup = bs.BeautifulSoup(urllib.request.urlopen(base_URL + \"Suche/S-\"+str(seite)+\"/Haus-Kauf/Nordrhein-Westfalen/Paderborn-Kreis/Paderborn/5,00-/130,00-/EURO--400000,00?enteredFrom=result_list\"\n",
    ").read(),'lxml')\n",
    "        print(\"Aktuelle Seite: \"+\"https://www.immobilienscout24.de/Suche/S-2/P-\"+str(seite)+\"/Haus-Kauf\")\n",
    "        \n",
    "        #resultlist-resultCount\n",
    "        for paragraph in soup.find_all(\"a\"):\n",
    "\n",
    "            if r\"/expose/\" in str(paragraph.get(\"href\")):\n",
    "                l.append(paragraph.get(\"href\").split(\"#\")[0])\n",
    "\n",
    "            l = list(set(l))\n",
    "\n",
    "        for item in l:\n",
    "\n",
    "            try:\n",
    "\n",
    "                soup = bs.BeautifulSoup(urllib.request.urlopen('https://www.immobilienscout24.de'+item).read(),'lxml')\n",
    "\n",
    "                data = pd.DataFrame(json.loads(str(soup.find_all(\"script\")).split(\"keyValues = \")[1].split(\"}\")[0]+str(\"}\")),index=[str(datetime.now())])\n",
    "\n",
    "                data[\"URL\"] = str(item)\n",
    "\n",
    "                beschreibung = []\n",
    "\n",
    "                for i in soup.find_all(\"pre\"):\n",
    "                    beschreibung.append(i.text)\n",
    "\n",
    "                data[\"beschreibung\"] = str(beschreibung)\n",
    "\n",
    "                df = df.append(data, sort=False)\n",
    "\n",
    "            except Exception as e: \n",
    "                print(str(datetime.now())+\": \" + str(e))\n",
    "                l = list(filter(lambda x: x != item, l))\n",
    "                print(\"ID \" + str(item) + \" entfernt.\")\n",
    "        print(\"Exportiert CSV\")\n",
    "        df.to_csv(\"C:/Users/Henning/rohdaten/\"+str(datetime.now())[:19].replace(\":\",\"\").replace(\".\",\"\")+\".csv\",\n",
    "                  sep=\";\",decimal=\",\",encoding = \"utf-8\",index_label=\"timestamp\")     \n",
    "\n",
    "        print(\"Loop \" + str(seite) + \" endet.\\n\")\n",
    "        \n",
    "except Exception as e: \n",
    "    print(str(datetime.now())+\": \" + str(e))\n",
    "\n",
    "print(\"FERTIG!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchgang 1\n",
      "Durchgang 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "n=0\n",
    "for i in os.listdir(\"C:/Users/Henning/rohdaten/\"):\n",
    "    n+=1\n",
    "    df = df.append(pd.read_csv(\"C:/Users/Henning/rohdaten/\"+str(i),sep=\";\",decimal=\",\",encoding=\"utf-8\"), sort=False)\n",
    "    print(\"Durchgang \"+str(n))\n",
    "    \n",
    "df.to_csv(\"C:/Users/Henning/rohdaten/summery_\"+str(datetime.now())[:19].replace(\":\",\"\").replace(\".\",\"\")+\".csv\",\n",
    "                  sep=\";\",decimal=\",\",encoding = \"utf-8\",index_label=\"timestamp\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
